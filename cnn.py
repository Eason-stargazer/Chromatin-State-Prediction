# -*- coding: utf-8 -*-
"""cnn

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1sDIaCzjVD8l-nuwKvBSE3m6RACS93jbv
"""

import pandas as pd
import numpy as np

df_seq = pd.read_csv("trainsequences.csv", names=["sequence"])
df_lbl = pd.read_csv("trainlabels.csv", names=["label"])

sequences = df_seq["sequence"].values
labels = df_lbl["label"].values
y = labels-1

def one_hot_encode_fixed(seq):
    mapping = {"A":[1,0,0,0],"C":[0,1,0,0],"G":[0,0,1,0],"T":[0,0,0,1]}
    arr = np.zeros((200,4), dtype=np.float32)
    for i, b in enumerate(seq[:200]):
        arr[i] = mapping.get(b, [0,0,0,0])
    return arr

X = np.array([one_hot_encode_fixed(s) for s in sequences])

print(X.shape)

# split the dataset into train and validation
from sklearn.model_selection import train_test_split

X_train, X_val, y_train, y_val = train_test_split(
    X, y,
    test_size=0.2,
    random_state=42,
    stratify=y
)

# address class imbalance
from sklearn.utils.class_weight import compute_class_weight

classes = np.unique(y_train)
class_weights = compute_class_weight(
    class_weight="balanced",
    classes=classes,
    y=y_train
)
class_weight_dict = dict(zip(classes, class_weights))

import tensorflow as tf
from tensorflow.keras import layers, models

L = X_train.shape[1]
num_classes = len(np.unique(y_train))

model = models.Sequential([
    layers.Input(shape=(L, 4)),

    layers.Conv1D(64, 15, activation="relu", padding="same"),
    layers.Conv1D(64, 15, activation="relu", padding="same"),
    layers.MaxPooling1D(2),

    layers.Conv1D(128, 15, activation="relu", padding="same"),
    layers.Conv1D(128, 15, activation="relu", padding="same"),
    layers.MaxPooling1D(2),

    layers.Conv1D(256, 15, activation="relu", padding="same"),
    layers.GlobalMaxPooling1D(),

    layers.Dense(512, activation="relu"),
    layers.Dropout(0.4),

    layers.Dense(num_classes, activation="softmax")
])

model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
    loss=tf.keras.losses.SparseCategoricalCrossentropy(),
    metrics=["accuracy"]
)

history = model.fit(
    X_train, y_train,
    validation_data=(X_val, y_val),
    epochs=8,
    batch_size=128,
    class_weight=class_weight_dict,
    verbose=1
)

from sklearn.metrics import classification_report

y_pred = np.argmax(model.predict(X_val), axis=1)
print(classification_report(y_val, y_pred, digits=3))